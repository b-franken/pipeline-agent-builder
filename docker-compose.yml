# Docker Compose for Multi-Agent AI Template
# Versions as of December 2025:
# - Python 3.14.2
# - PostgreSQL 18.1 with pgvector
# - ChromaDB 1.3.7

services:
  # ==========================================================================
  # Agent Application
  # ==========================================================================
  agent:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: agent-app
    depends_on:
      postgres:
        condition: service_healthy
      chroma:
        condition: service_healthy
    ports:
      - "${API_PORT:-8080}:8000"
    environment:
      # LLM Provider
      - PROVIDER=${PROVIDER:-openai}
      - DEFAULT_MODEL=${DEFAULT_MODEL:-gpt-4-turbo-preview}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      - GOOGLE_API_KEY=${GOOGLE_API_KEY:-}

      # Database
      - POSTGRES_URI=postgresql://agent:${POSTGRES_PASSWORD:-agent_secret}@postgres:5432/agent_db
      - USE_POSTGRES=true

      # ChromaDB
      - CHROMA_HOST=chroma
      - CHROMA_PORT=8000

      # Ollama (for local LLM mode)
      - OLLAMA_HOST=${OLLAMA_HOST:-http://ollama:11434}
      - OLLAMA_MODEL=${OLLAMA_MODEL:-llama3.2}
      - OLLAMA_EMBED_MODEL=${OLLAMA_EMBED_MODEL:-nomic-embed-text}

      # Optional services
      - E2B_API_KEY=${E2B_API_KEY:-}
      - TAVILY_API_KEY=${TAVILY_API_KEY:-}
    volumes:
      - agent_data:/app/data
    networks:
      - agent-network
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/health')"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  # ==========================================================================
  # PostgreSQL 18 with pgvector for checkpointing and vector search
  # ==========================================================================
  postgres:
    image: pgvector/pgvector:pg18
    container_name: agent-postgres
    environment:
      - POSTGRES_USER=agent
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-agent_secret}
      - POSTGRES_DB=agent_db
    volumes:
      # PostgreSQL 18+ uses version-specific PGDATA path
      - postgres_data:/var/lib/postgresql
      - ./docker/init-db.sql:/docker-entrypoint-initdb.d/init.sql:ro
    ports:
      - "${POSTGRES_PORT:-5432}:5432"
    networks:
      - agent-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U agent -d agent_db"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    restart: unless-stopped

  # ==========================================================================
  # ChromaDB 1.3.7 for vector memory
  # ==========================================================================
  chroma:
    image: chromadb/chroma:1.3.7
    container_name: agent-chroma
    environment:
      - IS_PERSISTENT=TRUE
      - PERSIST_DIRECTORY=/chroma/chroma
      - ANONYMIZED_TELEMETRY=FALSE
      # Authentication (optional, uncomment for production)
      # - CHROMA_SERVER_AUTHN_PROVIDER=chromadb.auth.token_authn.TokenAuthenticationServerProvider
      # - CHROMA_SERVER_AUTHN_CREDENTIALS=${CHROMA_TOKEN:-}
    volumes:
      - chroma_data:/chroma/chroma
    ports:
      - "${CHROMA_PORT:-8001}:8000"
    networks:
      - agent-network
    healthcheck:
      # ChromaDB 1.3+ image doesn't have curl - use bash TCP check
      test: ["CMD-SHELL", "timeout 2 bash -c '</dev/tcp/localhost/8000' || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 15s
    restart: unless-stopped

  # ==========================================================================
  # Next.js Frontend Dashboard
  # ==========================================================================
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: agent-frontend
    depends_on:
      agent:
        condition: service_healthy
    ports:
      - "${FRONTEND_PORT:-3000}:3000"
    environment:
      - NEXT_PUBLIC_API_URL=http://localhost:8080
    networks:
      - agent-network
    healthcheck:
      test: ["CMD", "node", "-e", "fetch('http://localhost:3000').then(r => process.exit(r.ok ? 0 : 1)).catch(() => process.exit(1))"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  # ==========================================================================
  # Ollama for local LLM (optional - use with: docker compose --profile local-llm up)
  # ==========================================================================
  ollama:
    image: ollama/ollama:latest
    container_name: agent-ollama
    profiles:
      - local-llm
    volumes:
      - ollama_data:/root/.ollama
    ports:
      - "${OLLAMA_PORT:-11434}:11434"
    networks:
      - agent-network
    healthcheck:
      test: ["CMD-SHELL", "ollama list || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    # GPU support (uncomment for NVIDIA GPU)
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]
    restart: unless-stopped

volumes:
  agent_data:
    driver: local
  postgres_data:
    driver: local
  chroma_data:
    driver: local
  ollama_data:
    driver: local

networks:
  agent-network:
    driver: bridge
